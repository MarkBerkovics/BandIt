{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92e7043-80e1-4a72-a93c-960fe18eb211",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfaf297-9ab2-4a53-a841-c03a10ca7694",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf71d7-b8f3-47e6-9ff8-a2e4dd7a5fa8",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe8063-4e23-4a5a-ade5-7010a6e0ff1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pretty-midi\n",
    "!pip install essentia\n",
    "!pip install resampy\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548aa23-8c78-4b77-a815-84ac099000f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo apt install -y fluidsynth\n",
    "!pip install midi2audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15328bc4-409e-4850-9929-4bef6bb449f5",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d38dc-4063-4901-b240-88ec03e66b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd236b0f-3dcc-45e3-8fb8-1e76859959ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b27ec7-fa40-467b-9a79-e0df94310cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813e3be-a4d2-411e-8fe9-c8aaf320d877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0913557-0881-475c-a3c7-11d2a7a5da83",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e372c0-8476-4b7d-ae5a-e4969e646e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Audio\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import pretty_midi\n",
    "from midi2audio import FluidSynth\n",
    "import numpy as np\n",
    "\n",
    "# Model\n",
    "from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652bd1c-d35f-46eb-af28-415539d18358",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b138f-61ba-4563-8e2b-ba0c1f195667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a3ed9-44c4-4256-b5ea-e50152bdd0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = \"../data\"\n",
    "midi_file_paths = glob.glob(f\"{data_folder}/.mid\")[:10]\n",
    "midi_files = [pretty_midi.PrettyMIDI(p) for p in midi_file_paths]\n",
    "print(f\"Working with {len(midi_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34368a-41bc-4ae7-810b-e6cd779716cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_title = \"Hotel_California_1\"\n",
    "single_midi = pretty_midi.PrettyMIDI(f\"{data_folder}/{test_title}.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979ce57-d62b-4e92-94e0-428c3ed341d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pop2Piano - out of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b66ff-7a24-432e-ad7c-98f8a35c43bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create wav file from midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565383f-3de0-48c3-b29e-9c1507425be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = FluidSynth()\n",
    "fs.midi_to_audio(f\"{data_folder}/{test_title}.mid\", f'../test_data/{test_title}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed2473-5586-4925-9c0b-f8bd0249ca71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Pop2Piano to generate a piano arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54417e-a1ae-4363-a10f-ca684f2fc66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(f\"../test_data/{test_title}.wav\", sr=44100)  # feel free to change the sr to a suitable value.\n",
    "model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n",
    "processor = Pop2PianoProcessor.from_pretrained(\"sweetcocoa/pop2piano\")\n",
    "\n",
    "inputs = processor(audio=audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "model_output = model.generate(input_features=inputs[\"input_features\"], composer=\"composer1\")\n",
    "tokenizer_output = processor.batch_decode(\n",
    "    token_ids=model_output, feature_extractor_output=inputs\n",
    ")[\"pretty_midi_objects\"][0]\n",
    "tokenizer_output.write(f\"../test_data/{test_title}_pop2piano.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfe828-2789-4ac8-89dd-f5e6c8a3e2a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make piano arrangement sound like drum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29402933-0440-428a-bfe6-2858a1ef58d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack = pretty_midi.PrettyMIDI(f\"../test_data/{test_title}_pop2piano.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c888205-06b0-4a0e-b131-effa77caf680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack.instruments[0].is_drum =True\n",
    "piano_to_drum_hack.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923052f-b0c8-4a65-af65-44c7221b28c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack.write(f\"../test_data/{test_title}_pop2piano_drum_hack.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70074391-eb41-45f9-97cc-c87c198d6e5b",
   "metadata": {},
   "source": [
    "# Custom implementation of T5\n",
    "Inspired by pop2piano! Check it out here: https://github.com/sweetcocoa/pop2piano/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87a496-0123-4fda-8122-895a5c5f0081",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's explore the T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8740b67b-1898-44a5-9d8b-c2b6ff1f8f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ca6d9-e4b0-4bae-984e-c7f791bd54c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's play around with a pretrained T5 model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b16d61a8-30a6-42fb-8ded-ed2d84d5c186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizers and model\n",
    "pretrained_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\") # vocab size is 32100.\n",
    "predtrained_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34d9de-8560-4d41-9ffb-7bd060e10da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for a phrase get the tokenised input ids\n",
    "input_ids = tokenizer(\"translate English to French: I am going to the party.\", return_tensors=\"pt\").input_ids\n",
    "# use the input ids to generte output\n",
    "outputs = model.generate(input_ids)\n",
    "# decode the output token ids to text\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "## Output --> \n",
    "## Ich werde zur Partei gehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad81d1-38ea-4986-9b8d-ec05fb435d31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's try some finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "541952d7-c0fb-464a-9beb-77c3e119f078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e8e75e1-ce7b-4629-95fc-280cdce0e8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_name</th>\n",
       "      <th>guitar_tracks</th>\n",
       "      <th>drum_tracks</th>\n",
       "      <th>standardized_guitar_bars</th>\n",
       "      <th>standardized_drum_bars</th>\n",
       "      <th>tokenized_guitar</th>\n",
       "      <th>tokenized_drums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/No_Son_Of_Mine.mid</td>\n",
       "      <td>Instrument(program=28, is_drum=False, name=\"No...</td>\n",
       "      <td>Instrument(program=16, is_drum=True, name=\"No ...</td>\n",
       "      <td>[[], [], [], [], [], [Note(start=1.022917, end...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 165357, 164307, 163344, 162387...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/Deja-Vu.mid</td>\n",
       "      <td>Instrument(program=30, is_drum=False, name=\"Gu...</td>\n",
       "      <td>Instrument(program=0, is_drum=True, name=\"Drums\")</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [Note(sta...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [Note(start=1...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 168616, 82913, 711...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 212531, 147704, 14708...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 song_name                                      guitar_tracks  \\\n",
       "0  data/No_Son_Of_Mine.mid  Instrument(program=28, is_drum=False, name=\"No...   \n",
       "1         data/Deja-Vu.mid  Instrument(program=30, is_drum=False, name=\"Gu...   \n",
       "\n",
       "                                         drum_tracks  \\\n",
       "0  Instrument(program=16, is_drum=True, name=\"No ...   \n",
       "1  Instrument(program=0, is_drum=True, name=\"Drums\")   \n",
       "\n",
       "                            standardized_guitar_bars  \\\n",
       "0  [[], [], [], [], [], [Note(start=1.022917, end...   \n",
       "1  [[], [], [], [], [], [], [], [], [], [Note(sta...   \n",
       "\n",
       "                              standardized_drum_bars  \\\n",
       "0  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
       "1  [[], [], [], [], [], [], [], [], [Note(start=1...   \n",
       "\n",
       "                                    tokenized_guitar  \\\n",
       "0  [5, 5, 5, 5, 5, 165357, 164307, 163344, 162387...   \n",
       "1  [5, 5, 5, 5, 5, 5, 5, 5, 5, 168616, 82913, 711...   \n",
       "\n",
       "                                     tokenized_drums  \n",
       "0  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  \n",
       "1  [5, 5, 5, 5, 5, 5, 5, 5, 212531, 147704, 14708...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"../../midi_df_2199.pkl\")\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846add8f-b16b-405e-92a0-ef84da5a6a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df[\"tokenized_guitar\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b52bf09-0378-47ba-8368-199b4c51f45f",
   "metadata": {},
   "source": [
    "### Tokenize with t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d77d11f0-b760-40c5-b720-eba26dbd0106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1a6e3f0d-d8f9-4666-9795-3dafc93f83cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[5, 5, 5, 5, 5, 165357, 164307, 163344, 162387, 161460, 160533, 159366, 158322, 157372, 156384, 155451, 154554, 153580, 152724, 151878, 151032, 150226, 149141, 148290, 147523, 146739, 145988, 145203, 144313, 143593, 142861, 142204, 141529, 140677, 140034, 139408, 138811, 138192, 137596, 136953, 136402, 135839, 135292, 134784, 133968, 133420, 132890, 132387, 131908, 131460, 130923, 130476, 130015, 129594, 129176, 128490, 128098, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 120200, 119936, 119693, 119443, 119235, 119003, 118789, 118352, 118146, 117938, 117750, 117557, 117387, 117171, 116995, 116825, 116643, 116466, 116195, 116056, 115892, 115748, 115586, 115441, 115284, 115143, 114995, 114864, 114704, 114422, 114308, 114185, 114076, 113949, 113844, 113729, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 111430, 111373, 111266, 111215, 111156, 111110, 111014, 110974, 110923, 110873, 110817, 110774, 110706, 110622, 110596, 110544, 110513, 110450, 110409, 110357, 110317, 110255, 5, 6]'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(str(df[\"tokenized_guitar\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4ae6c2-7f36-401e-814e-2d91690eede8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f57f38b-1a3e-470a-b64c-fd8ccf515a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m input_ids, attention_mask \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39minput_ids, encoding\u001b[38;5;241m.\u001b[39mattention_mask\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# encode the targets\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m target_encoding \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlongest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_target_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m labels \u001b[38;5;241m=\u001b[39m target_encoding\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# replace padding token id's of the labels by -100 so it's ignored by the loss\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2840\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2838\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2839\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2840\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2842\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2898\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2895\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   2897\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text):\n\u001b[0;32m-> 2898\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2899\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2900\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2901\u001b[0m     )\n\u001b[1;32m   2903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_valid_text_input(text_pair):\n\u001b[1;32m   2904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2905\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2906\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2907\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "# the following 2 hyperparameters are task-specific\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "# goal\n",
    "task_prefix = \"translate guitar to drums\"\n",
    "\n",
    "# Suppose we have the following training examples:\n",
    "input_sequences = df[\"tokenized_guitar\"].apply(lambda x: ''.join(str(x)))\n",
    "output_sequences = df[\"tokenized_drums\"].apply(lambda x: ''.join(str(x)))\n",
    "# encode the inputs\n",
    "\n",
    "encoding = tokenizer(\n",
    "    [task_prefix + sequence for sequence in input_sequences],\n",
    "    padding=\"longest\",\n",
    "    max_length=max_source_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# encode the targets\n",
    "target_encoding = tokenizer(\n",
    "    output_sequences,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_target_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "labels = target_encoding.input_ids\n",
    "\n",
    "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "# forward pass\n",
    "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c7c9ac-e970-4765-b700-716de996df6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "guitar_vector = df[\"tokenized_guitar\"][:2].apply(eval).to_numpy()\n",
    "drum_vector = df[\"tokenized_drums\"][:2].apply(eval).to_numpy()\n",
    "\n",
    "ragged_guitar_tensor = tf.ragged.constant(guitar_vector)\n",
    "padded_guitar_tensor = ragged_guitar_tensor.to_tensor(default_value=0)\n",
    "\n",
    "ragged_drum_tensor = tf.ragged.constant(drum_vector)\n",
    "padded_drum_tensor = ragged_drum_tensor.to_tensor(default_value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33e7f1d-680b-488c-ab78-f9d5334ae812",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "guitar_vector_padded = np.pad(guitar_vector, 'pad_width', mode='constant') \n",
    "guitar_vector_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5e8343-0c75-460a-8be8-53280652c59c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Add padding to rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b225cac2-fbf1-4301-878c-60fdd17adb9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#df['tokenized_guitar_list'] = df['tokenized_guitar'].apply(eval)\n",
    "#df['tokenized_drums_list'] = df['tokenized_drums'].apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b453388-4d3e-4998-aa0a-686007083e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1005"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_to_max_len_list = max(df['tokenized_guitar'].apply(lambda x : len(x)))\n",
    "pad_to_max_len_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "84f5733e-26b4-4056-af29-e4644fadeb8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df['tokenized_guitar_padded'] = df['tokenized_guitar'].apply(\n",
    "    lambda x: np.pad(x, pad_width=(0, (pad_to_max_len_list-len(x))), mode='constant', constant_values=0))\n",
    "df['tokenized_drums_padded'] = df['tokenized_drums'].apply(\n",
    "    lambda x: np.pad(x, pad_width=(0, (pad_to_max_len_list-len(x))), mode='constant', constant_values=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6936bc65-ef1b-4ea9-a1cb-c99649194da6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2199,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tokenized_guitar_padded'].to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaddf9d1-5406-457f-8552-0504aae3c2fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_63504/2665179827.py:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)\n",
      "  padded_guitar_tensor = torch.IntTensor(df['tokenized_guitar_padded'].apply(lambda x: x.astype(\"int32\")))\n"
     ]
    }
   ],
   "source": [
    "padded_guitar_tensor = torch.IntTensor(df['tokenized_guitar_padded'].apply(lambda x: x.astype(\"int32\")))\n",
    "padded_drum_tensor = torch.IntTensor(df['tokenized_drums_padded'].apply(lambda x: x.astype(\"int32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c89cd3e-1034-43f6-880d-d45604ce3a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2199, 1005])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_guitar_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99368678-3ea8-4c0a-b221-305f3803c9b1",
   "metadata": {},
   "source": [
    "### Create a T5 model with a custom config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8ed1ec6-cfdc-4da8-9711-6fd71264d176",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a6fe938-b443-4890-bd8c-30d39b25a825",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This is basically a test thing\n",
    "embedding = torch.nn.Embedding(num_embeddings=213356, embedding_dim=100)\n",
    "output = embedding(padded_guitar_tensor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68b6d275-132c-4ace-a4fe-ea315151473b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"classifier_dropout\": 0.0,\n",
       "  \"d_ff\": 2048,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 512,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 1,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"num_decoder_layers\": 6,\n",
       "  \"num_heads\": 8,\n",
       "  \"num_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"transformers_version\": \"4.39.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 213356\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the config!\n",
    "config = T5Config()\n",
    "config.vocab_size = 213356\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92e3055d-5206-4b70-b987-eff35aede16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "custom_model = T5ForConditionalGeneration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadaf777-6e17-41b1-81d5-ce3f91f25c82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# forward pass\n",
    "custom_model(input_ids=padded_guitar_tensor[:100], labels=padded_drum_tensor[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be862023-ce0b-4993-9817-5dc0d2fa6a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_input = df[\"tokenized_guitar\"][800]\n",
    "input_ids = tokenizer(f\"{test_input}\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids, max_length=1000)\n",
    "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(len(decoded))\n",
    "print(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44d83d2-3f7b-48a4-9957-6c87157d3bbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(eval(decoded.split(\"[\")[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b46d9-2708-4414-a970-4653457474be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"tokenized_drums\"][800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b5c09a-5d8b-4aa0-8497-e67ad116b6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df[\"tokenized_guitar\"][800]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cae5b2-8940-43d9-9b63-7e9b884a8ffb",
   "metadata": {},
   "source": [
    "Song at idx 500: (5, 5, 168967, 86700, 168207, 82728, 167405, 78644, 166499, 74742, 165637, 71124, 164729, 67670, 163806, 64600, 162910, 61545, 162000, 58782, 161132, 56356, 160270, 53915, 159321, 51697, 158392, 49733, 157471, 47920)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
