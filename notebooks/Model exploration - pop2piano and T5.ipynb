{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f92e7043-80e1-4a72-a93c-960fe18eb211",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfaf297-9ab2-4a53-a841-c03a10ca7694",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cf71d7-b8f3-47e6-9ff8-a2e4dd7a5fa8",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fe8063-4e23-4a5a-ade5-7010a6e0ff1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pretty-midi\n",
    "!pip install essentia\n",
    "!pip install resampy\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548aa23-8c78-4b77-a815-84ac099000f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!sudo apt install -y fluidsynth\n",
    "!pip install midi2audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15328bc4-409e-4850-9929-4bef6bb449f5",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91d38dc-4063-4901-b240-88ec03e66b05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd236b0f-3dcc-45e3-8fb8-1e76859959ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b27ec7-fa40-467b-9a79-e0df94310cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e813e3be-a4d2-411e-8fe9-c8aaf320d877",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0913557-0881-475c-a3c7-11d2a7a5da83",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e372c0-8476-4b7d-ae5a-e4969e646e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Audio\n",
    "import os\n",
    "import librosa\n",
    "import glob\n",
    "import pretty_midi\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "# Model\n",
    "from transformers import Pop2PianoForConditionalGeneration, Pop2PianoProcessor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9652bd1c-d35f-46eb-af28-415539d18358",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08b138f-61ba-4563-8e2b-ba0c1f195667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.getcwd()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3a3ed9-44c4-4256-b5ea-e50152bdd0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = \"../data\"\n",
    "midi_file_paths = glob.glob(f\"{data_folder}/.mid\")[:10]\n",
    "midi_files = [pretty_midi.PrettyMIDI(p) for p in midi_file_paths]\n",
    "print(f\"Working with {len(midi_files)} files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e34368a-41bc-4ae7-810b-e6cd779716cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_title = \"Hotel_California_1\"\n",
    "single_midi = pretty_midi.PrettyMIDI(f\"{data_folder}/{test_title}.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1979ce57-d62b-4e92-94e0-428c3ed341d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pop2Piano - out of the box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6b66ff-7a24-432e-ad7c-98f8a35c43bc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create wav file from midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565383f-3de0-48c3-b29e-9c1507425be0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fs = FluidSynth()\n",
    "fs.midi_to_audio(f\"{data_folder}/{test_title}.mid\", f'../test_data/{test_title}.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aed2473-5586-4925-9c0b-f8bd0249ca71",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Use Pop2Piano to generate a piano arrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54417e-a1ae-4363-a10f-ca684f2fc66e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio, sr = librosa.load(f\"../test_data/{test_title}.wav\", sr=44100)  # feel free to change the sr to a suitable value.\n",
    "model = Pop2PianoForConditionalGeneration.from_pretrained(\"sweetcocoa/pop2piano\")\n",
    "processor = Pop2PianoProcessor.from_pretrained(\"sweetcocoa/pop2piano\")\n",
    "\n",
    "inputs = processor(audio=audio, sampling_rate=sr, return_tensors=\"pt\")\n",
    "model_output = model.generate(input_features=inputs[\"input_features\"], composer=\"composer1\")\n",
    "tokenizer_output = processor.batch_decode(\n",
    "    token_ids=model_output, feature_extractor_output=inputs\n",
    ")[\"pretty_midi_objects\"][0]\n",
    "tokenizer_output.write(f\"../test_data/{test_title}_pop2piano.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cfe828-2789-4ac8-89dd-f5e6c8a3e2a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Make piano arrangement sound like drum\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29402933-0440-428a-bfe6-2858a1ef58d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack = pretty_midi.PrettyMIDI(f\"../test_data/{test_title}_pop2piano.mid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c888205-06b0-4a0e-b131-effa77caf680",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack.instruments[0].is_drum =True\n",
    "piano_to_drum_hack.instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923052f-b0c8-4a65-af65-44c7221b28c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "piano_to_drum_hack.write(f\"../test_data/{test_title}_pop2piano_drum_hack.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70074391-eb41-45f9-97cc-c87c198d6e5b",
   "metadata": {},
   "source": [
    "# Custom implementation of T5\n",
    "Inspired by pop2piano! Check it out here: https://github.com/sweetcocoa/pop2piano/tree/main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87a496-0123-4fda-8122-895a5c5f0081",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let's explore the T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8740b67b-1898-44a5-9d8b-c2b6ff1f8f9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5Config, T5ForConditionalGeneration, T5Tokenizer, T5Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428ca6d9-e4b0-4bae-984e-c7f791bd54c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's play around with a pretrained T5 model first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b16d61a8-30a6-42fb-8ded-ed2d84d5c186",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# load the tokenizers and model\n",
    "pretrained_tokenizer = T5Tokenizer.from_pretrained(\"t5-small\") # vocab size is 32100.\n",
    "predtrained_model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a34d9de-8560-4d41-9ffb-7bd060e10da4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for a phrase get the tokenised input ids\n",
    "input_ids = tokenizer(\"translate English to French: I am going to the party.\", return_tensors=\"pt\").input_ids\n",
    "# use the input ids to generte output\n",
    "outputs = model.generate(input_ids)\n",
    "# decode the output token ids to text\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "## Output --> \n",
    "## Ich werde zur Partei gehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ad81d1-38ea-4986-9b8d-ec05fb435d31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Let's try some finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "541952d7-c0fb-464a-9beb-77c3e119f078",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e8e75e1-ce7b-4629-95fc-280cdce0e8c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>song_name</th>\n",
       "      <th>guitar_tracks</th>\n",
       "      <th>drum_tracks</th>\n",
       "      <th>standardized_guitar_bars</th>\n",
       "      <th>standardized_drum_bars</th>\n",
       "      <th>tokenized_guitar</th>\n",
       "      <th>tokenized_drums</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>data/No_Son_Of_Mine.mid</td>\n",
       "      <td>Instrument(program=28, is_drum=False, name=\"No...</td>\n",
       "      <td>Instrument(program=16, is_drum=True, name=\"No ...</td>\n",
       "      <td>[[], [], [], [], [], [Note(start=1.022917, end...</td>\n",
       "      <td>[[], [], [], [], [], [], [], [], [], [], [], [...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 165357, 164307, 163344, 162387...</td>\n",
       "      <td>[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                song_name  \\\n",
       "0           0  data/No_Son_Of_Mine.mid   \n",
       "\n",
       "                                       guitar_tracks  \\\n",
       "0  Instrument(program=28, is_drum=False, name=\"No...   \n",
       "\n",
       "                                         drum_tracks  \\\n",
       "0  Instrument(program=16, is_drum=True, name=\"No ...   \n",
       "\n",
       "                            standardized_guitar_bars  \\\n",
       "0  [[], [], [], [], [], [Note(start=1.022917, end...   \n",
       "\n",
       "                              standardized_drum_bars  \\\n",
       "0  [[], [], [], [], [], [], [], [], [], [], [], [...   \n",
       "\n",
       "                                    tokenized_guitar  \\\n",
       "0  [5, 5, 5, 5, 5, 165357, 164307, 163344, 162387...   \n",
       "\n",
       "                                     tokenized_drums  \n",
       "0  [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../midi_df_full.csv\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f57f38b-1a3e-470a-b64c-fd8ccf515a1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google-t5/t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google-t5/t5-small\")\n",
    "\n",
    "# the following 2 hyperparameters are task-specific\n",
    "max_source_length = 512\n",
    "max_target_length = 128\n",
    "\n",
    "# Suppose we have the following training examples:\n",
    "input_sequences = df[\"tokenized_guitar\"][:30].to_list()\n",
    "output_sequences = df[\"tokenized_drums\"][:30].to_list()\n",
    "\n",
    "\n",
    "# encode the inputs\n",
    "task_prefix = \"translate guitar to drums\"\n",
    "\n",
    "encoding = tokenizer(\n",
    "    [task_prefix + sequence for sequence in input_sequences],\n",
    "    padding=\"longest\",\n",
    "    max_length=max_source_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "\n",
    "input_ids, attention_mask = encoding.input_ids, encoding.attention_mask\n",
    "\n",
    "# encode the targets\n",
    "target_encoding = tokenizer(\n",
    "    output_sequences,\n",
    "    padding=\"longest\",\n",
    "    max_length=max_target_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "labels = target_encoding.input_ids\n",
    "\n",
    "# replace padding token id's of the labels by -100 so it's ignored by the loss\n",
    "labels[labels == tokenizer.pad_token_id] = -100\n",
    "\n",
    "# forward pass\n",
    "loss = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels).loss\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be862023-ce0b-4993-9817-5dc0d2fa6a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to drums: [5, 91376, 168933, 168599, 168159, 167837, 167349, 166984, 166444, 166113, 165585, 165218, 164652, 89376, 89168, 88986, 108102, 84419, 166245, 87813, 165890, 87643, 81801, 100528, 80905, 80577, 107187, 103470, 1578\n"
     ]
    }
   ],
   "source": [
    "test_input = df[\"tokenized_guitar\"][2000]\n",
    "input_ids = tokenizer(f\"translate guitar to drums: {test_input}\", return_tensors=\"pt\").input_ids\n",
    "outputs = model.generate(input_ids, max_length = 200)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3c1c4f-f879-476f-a3f6-13d6749988a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m118",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m118"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
